
import SbtDependency from '@site/src/components/SbtDependency';

# Postgres Runtime

`PostgresRuntime` provides a simpler, yet less powerful alternative to full-fledged event-sourcing solutions like Akka/Pekko.

It stores events in a database table without maintaining any state in memory. Each interaction with the runtime reads events directly from the journal. This design results in higher latency but reduces memory usage.

## Usage

Follow these steps to use the Postgres runtime. Detailed explanations are provided in the sections below:

1. Add the dependency:
<SbtDependency moduleName={"workflows4s-doobie"}/>
2. Include the [database migration](https://github.com/business4s/workflows4s/tree/main/workflows4s-doobie/src/main/resources/schema) as part of your application lifecycle.
3. Implement the `EventCodec`.
4. Use the runtime.

### Database Migrations

Postgres runtime requires a basic database table to store events. While alternative schemas are possible, they may necessitate a custom `WorkflowStorage`. Refer to [Other Databases](#other-databases--custom-storages) for more details.

<!-- @formatter:off -->
```sql file=../../workflows4s-doobie/src/main/resources/schema/postgres-schema.sql start=doc_start end=doc_end
```
<!-- @formatter:on -->

This implementation makes several assumptions and is intentionally kept simple. For more demanding use cases, consider using a different runtime or implementing a custom storage solution.

### Event Codec

Events are stored in the database as binary data. The `EventCodec` is used to handle the serialization and deserialization of these events.

### Example

Here is an example of using the Postgres runtime:

```scala file=./main/scala/workflows4s/example/docs/doobie/PostgresExample.scala start=doc_start end=doc_end
```

## Locking the Workflow

Consider the following scenario:

1. A workflow awaits two signals in parallel.
2. Both signals arrive simultaneously.
3. Only one path of the workflow can be followed.

To address this, workflows are locked, ensuring that only a single signal is processed at a time.

### Workflow ID

Locking is implemented using [PostgreSQL advisory locks](https://www.postgresql.org/docs/current/explicit-locking.html#ADVISORY-LOCKS), which require a single `BIGINT` as a lock identifier. For simplicity, `Long` values are used as `WorkflowId`s and serve directly as lock IDs.

## Other Databases & Custom Storages

Support for additional DBMSs or alternative workflow storage approaches can be added by implementing the `WorkflowStorage` interface. This interface specifies how to:

- Save and read events
- Lock workflows

By extending `WorkflowStorage`, you can adapt the runtime to fit your specific requirements.
